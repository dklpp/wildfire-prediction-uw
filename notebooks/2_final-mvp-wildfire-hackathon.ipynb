{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":80397,"databundleVersionId":8656343,"sourceType":"competition"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Demo CNN for Wildfire Growth Prediction\n\nBelow is starter code for a cnn solution to solve the wildfire growth challenge!\n\nWe provide infrastructure and helper functions to call and process the data.\n\nIt is up to your team to fill in necessary blanks and improve the pipeline.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport rasterio as rio\nimport os\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport torch.nn.functional as F\n\n# Paths for data and fires\ndata_path = '/kaggle/input/wildfire-hackathon-kaggle/Wildfire_Hackathon_Complete/'\ntrain_path = data_path + \"Train/\"\ntest_path = data_path + \"Test/\"\ntr_fnums = [\"fire1209\", \"fire1298\", \"fire1386\", \"fire2034\", \"fire2210\", \"fire2211\", \"fire2212\"]\nte_fnums = [\"fire2214\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-25T19:42:08.165513Z","iopub.execute_input":"2024-05-25T19:42:08.166059Z","iopub.status.idle":"2024-05-25T19:42:12.111415Z","shell.execute_reply.started":"2024-05-25T19:42:08.166024Z","shell.execute_reply":"2024-05-25T19:42:12.110344Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Util variables\ndevice = 'cuda'\ntarget_shape = (528, 720)\n\n# Util functions\ndef pad_to_fit(d, shape):\n    h, w = d.shape\n    pad_h = shape[0] - h\n    pad_w = shape[1] - w\n    if pad_h > 0 or pad_w > 0:\n        pad_top = pad_h // 2\n        pad_bottom = pad_h - pad_top\n        pad_left = pad_w // 2\n        pad_right = pad_w - pad_left\n\n        d = np.pad(d, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)\n    return d\n\ndef normalize(d):\n    m = np.mean(d)\n    s = np.std(d)\n    return (d - m)/s\n\ndef tif2np(tif):\n    with rio.open(tif) as src:\n        data = src.read(1)  # Read the first band\n    return pad_to_fit(np.nan_to_num(data, nan=0.0), target_shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T19:42:12.113267Z","iopub.execute_input":"2024-05-25T19:42:12.114121Z","iopub.status.idle":"2024-05-25T19:42:12.122388Z","shell.execute_reply.started":"2024-05-25T19:42:12.114083Z","shell.execute_reply":"2024-05-25T19:42:12.121319Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Functions to load data\n\nThe load fire function loads and processes data for the denoted fire. The fire is then stacked into a numpy array.\n\nThe load day function loads in a day of data for a specified fire. \n\n<ins>**Additional data should be loaded and specified into this function**.<ins>","metadata":{}},{"cell_type":"code","source":"\ndef load_day(path, day):\n    # fire_weather\n    fwi = path+'/fire_weather/fire_weather_index_day{}.tif'.format(day)\n    fwi = normalize(tif2np(fwi))\n    # weather relative humidity\n    wrh = path+'/weather/noon_relative_humidity_day{}.tif'.format(day)\n    wrh = normalize(tif2np(wrh))\n    # weather wind speed\n    wws = path+'/weather/noon_wind_speed_day{}.tif'.format(day)\n    wws = normalize(tif2np(wws))\n    \n    # Add more data here\n    #...\n  #  wap = path+'/weather/24hr_accumulated_precipitation_day{}.tif'.format(day)\n  #  wap = normalize(tif2np(wap))\n\n    # initial spread index\n    fis = path+'/fire_weather/initial_spread_index_day{}.tif'.format(day)\n    fis = normalize(tif2np(fis))\n    \n    fbu = path+'/fire_weather/build_up_index_day{}.tif'.format(day)\n    fbu = normalize(tif2np(fbu))\n    \n#     fdc = path+ '/fire_weather/drought_code_day{}.tif'.format(day)\n#     fdc = normalize(tif2np(fdc))\n    \n    wmt = path+'/weather/24hr_max_temperature_day{}.tif'.format(day)\n    wmt = normalize(tif2np(wmt))\n    \n#     fdm = path+'/fire_weather/duff_moisture_code_day{}.tif'.format(day)\n#     fdm = normalize(tif2np(fdm))\n    \n#     fff = path+'/fire_weather/fine_fuel_moisture_code_day{}.tif'.format(day)\n#     fff = normalize(tif2np(fff))\n    \n    wnw = path+'/weather/noon_wind_direction_day{}.tif'.format(day)\n    wnw = normalize(tif2np(wnw))\n    \n    return [fwi, wrh, wws, fis, fbu, wmt]#, fdm, fff]#, wnw]#, wap]#, fis]\n\ndef load_fire(fire_num, split = \"Train\"):\n    path = train_path + fire_num\n    if split == \"Test\":\n        path = test_path + fire_num\n    \n    ftif = path + \"/fire/{}.tif\".format(fire_num)\n    if split == \"Test\":\n        ftif = path + \"/fire/{}_train.tif\".format(fire_num)\n    fdata = tif2np(ftif)\n\n    minjd, maxjd = int(np.min(fdata[np.nonzero(fdata)])), int(np.max(fdata))\n    lastjd = maxjd\n    if split == \"Test\":\n        maxjd += 21\n    \n    elev = normalize(tif2np(path+'/topography/dem.tif'))\n    slope = normalize(tif2np(path+'/topography/slope.tif'))\n    fuels = tif2np(path+'/fuels/fbp_fuels.tif')\n    ignition = tif2np(path+'/fire/ignitions.tif')\n\n    dataset = []\n    gt = ignition\n    cfire = ignition\n    for d in range(minjd, maxjd):\n        data = {}\n\n        fuels[cfire != 0] = 0\n        ft = [fuels]\n        ft.extend([cfire, gt, slope, elev])\n        ft.extend(load_day(path, d))\n        ft = np.stack(ft)\n        data['ft'] = ft\n\n        if d < lastjd:\n            gt = fdata == float(d)\n            data['gt'] = gt\n\n        cfire = np.logical_or(cfire ,gt)\n        \n        dataset.append(data)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:15:11.786783Z","iopub.execute_input":"2024-05-25T20:15:11.787152Z","iopub.status.idle":"2024-05-25T20:15:11.802433Z","shell.execute_reply.started":"2024-05-25T20:15:11.787125Z","shell.execute_reply":"2024-05-25T20:15:11.801291Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Create the datasets and dataloaders\n\n<ins>Create/implement data augmentations/transformations here<ins>","metadata":{}},{"cell_type":"code","source":"class FireDataset(Dataset):\n    def __init__(self, split=\"Train\"):\n        fnums = tr_fnums if split==\"Train\" else te_fnums\n        self.dataset = []\n        for fnum in fnums:\n            self.dataset.extend(load_fire(fnum, split=split))\n        print(len(self.dataset))\n        print(self.dataset[0].keys())\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        return self.dataset[idx]\n    \ntrainset = FireDataset(split=\"Train\")\ntrainset, valset = torch.utils.data.random_split(trainset, [0.9,0.1])\ntestset = FireDataset(split=\"Test\")\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True)\nvalloader = torch.utils.data.DataLoader(valset, batch_size=8, shuffle=True)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:15:13.056214Z","iopub.execute_input":"2024-05-25T20:15:13.057068Z","iopub.status.idle":"2024-05-25T20:15:54.238523Z","shell.execute_reply.started":"2024-05-25T20:15:13.057033Z","shell.execute_reply":"2024-05-25T20:15:54.237519Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"245\ndict_keys(['ft', 'gt'])\n30\ndict_keys(['ft', 'gt'])\n","output_type":"stream"}]},{"cell_type":"code","source":"trainset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define the network/model\n\nIn this example, we define a simple 2 layer cnn model. \n\n<ins>**Modify the model as you see fit!**<ins>","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass FuelEmbeddings(nn.Module):\n    def __init__(self, embedding_dim):\n        super(FuelEmbeddings, self).__init__()\n\n        unique_values = [0, 1, 2, 3, 4, 7, 13, 31, 101, 425, 635, 650, 665]\n        self.unique_values = torch.tensor(unique_values).to(device)  # Unique values in the categorical feature\n        self.embedding_dim = embedding_dim\n        self.embedding = nn.Embedding(num_embeddings=len(unique_values), embedding_dim=embedding_dim)\n\n    def forward(self, categorical_feature):\n        # (B,H,W) -> (B,H,W,U) wher U is unique values count\n        mask = categorical_feature.unsqueeze(-1) == self.unique_values\n        matching_indices = torch.argmax(mask.int(), dim=-1)\n\n        # Apply embedding and reshape\n        # (B,H,W,U) -> (B,H,W,6) -> (B,6,H,W) in default setting\n        embedded_fuel = self.embedding(matching_indices)\n        embedded_reshaped_fuel = embedded_fuel.permute(0, 3, 1, 2)\n\n        return embedded_reshaped_fuel\n\nclass CNN1(nn.Module):\n    def __init__(self, embedding_dim=6, num_features=8):\n        super(CNN1, self).__init__()\n\n        self.fuelembedding = FuelEmbeddings(embedding_dim)\n\n        # (266, 433)\n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(in_channels=(embedding_dim+num_features-1), out_channels=8, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=8),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=16),\n            nn.ReLU(inplace=True)\n        )\n        self.conv_block2a = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=8),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=32),\n            nn.ReLU(inplace=True)\n        )\n        self.conv_block2b = nn.Sequential(\n            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=16),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=16, out_channels=1, kernel_size=3, stride=1, padding=1),\n\n        )\n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=8),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=8, out_channels=1, kernel_size=3, stride=1, padding=1)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        categorical_feature = x[:, 0, :, :]  # Extract the categorical feature\n        embedded_fuel = self.fuelembedding(categorical_feature)  # Transform the categorical feature\n\n        # Replace the original categorical feature with the embedded feature\n        x = torch.cat((embedded_fuel, x[:, 1:, :, :]), dim=1)\n\n        x = self.conv_block1(x)\n        x = self.conv_block2a(x)\n        x = self.conv_block2b(x)\n        #x = self.conv_block2(x)\n        out = self.sigmoid(x)\n\n        return out\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:02:00.841512Z","iopub.execute_input":"2024-05-25T20:02:00.842149Z","iopub.status.idle":"2024-05-25T20:02:00.862623Z","shell.execute_reply.started":"2024-05-25T20:02:00.842117Z","shell.execute_reply":"2024-05-25T20:02:00.861488Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class CNN1(nn.Module):\n    def __init__(self, embedding_dim=6, num_features=8):\n        super(CNN1, self).__init__()\n\n        self.fuelembedding = FuelEmbeddings(embedding_dim)\n\n        # (266, 433)\n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(in_channels=(embedding_dim+num_features-1), out_channels=8, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=8),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=16),\n            nn.ReLU(inplace=True)\n        )\n        self.conv_block1aa = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=16),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=32),\n            nn.ReLU(inplace=True)\n        )\n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=16),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=16, out_channels=1, kernel_size=3, stride=1, padding=1)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        categorical_feature = x[:, 0, :, :]  # Extract the categorical feature\n        embedded_fuel = self.fuelembedding(categorical_feature)  # Transform the categorical feature\n\n        # Replace the original categorical feature with the embedded feature\n        x = torch.cat((embedded_fuel, x[:, 1:, :, :]), dim=1)\n\n        x = self.conv_block1(x)\n        x = self.conv_block1aa(x)\n        x = self.conv_block2(x)\n        out = self.sigmoid(x)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:16:04.980360Z","iopub.execute_input":"2024-05-25T20:16:04.981032Z","iopub.status.idle":"2024-05-25T20:16:04.992866Z","shell.execute_reply.started":"2024-05-25T20:16:04.980998Z","shell.execute_reply":"2024-05-25T20:16:04.991953Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class CNN2_1458(nn.Module):\n    def __init__(self, embedding_dim=6, num_features=14):\n        super(CNN2_1458, self).__init__()\n\n        self.fuelembedding = FuelEmbeddings(embedding_dim)\n\n        # Initial Convolution Block\n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(in_channels=(embedding_dim + num_features - 1), out_channels=8, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=8),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=16),\n            nn.ReLU(inplace=True)\n        )\n\n        # Residual Convolution Block 2a\n        self.conv_block2a = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=32),\n            nn.ReLU(inplace=True)\n        )\n\n        # Residual Convolution Block 2b\n        self.conv_block2b = nn.Sequential(\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=64),\n            nn.ReLU(inplace=True)\n        )\n\n        # Final Convolution Block\n        self.conv_block3 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=16),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=16, out_channels=1, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.dropout = nn.Dropout(p=0.5)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        categorical_feature = x[:, 0, :, :]  # Extract the categorical feature\n        embedded_fuel = self.fuelembedding(categorical_feature)  # Transform the categorical feature\n\n        # Ensure the embedded feature matches the spatial dimensions of other features\n        embedded_fuel = embedded_fuel.permute(0, 3, 1, 2)  # Convert to (N, C, H, W) format\n        embedded_fuel = nn.functional.interpolate(embedded_fuel, size=(x.size(2), x.size(3)), mode='bilinear', align_corners=False)\n\n        # Replace the original categorical feature with the embedded feature\n        x = torch.cat((embedded_fuel, x[:, 1:, :, :]), dim=1)\n\n        x = self.conv_block1(x)\n        x = self.conv_block2a(x) + x  # Residual connection\n        x = self.conv_block2b(x) + x  # Residual connection\n        x = self.conv_block3(x)\n        x = self.dropout(x)\n        out = self.sigmoid(x)\n\n        return out\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Loss function\n\n<ins>**Create/define/specify your own loss function here!**<ins>","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass IoULoss(nn.Module):\n    def __init__(self, threshold=0.5):\n        super(IoULoss, self).__init__()\n        self.threshold = threshold\n\n    def forward(self, outputs, labels):\n        # threshold condition is not differentiable so just use softmaxed data\n        # Flatten the tensors\n        outputs = outputs.view(-1)\n        labels = labels.view(-1)\n\n        # Compute the intersection\n        intersection = (outputs * labels).sum()\n\n        # Compute the union\n        union = outputs.sum() + labels.sum() - intersection\n        iou = intersection / (union + 1e-6)  # Add a small epsilon for numerical stability\n        loss = 1 - iou\n        return loss","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:02:10.264648Z","iopub.execute_input":"2024-05-25T20:02:10.265530Z","iopub.status.idle":"2024-05-25T20:02:10.272482Z","shell.execute_reply.started":"2024-05-25T20:02:10.265495Z","shell.execute_reply":"2024-05-25T20:02:10.271398Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"#### Metrics for evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, jaccard_score, f1_score","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:02:11.454208Z","iopub.execute_input":"2024-05-25T20:02:11.455002Z","iopub.status.idle":"2024-05-25T20:02:11.459340Z","shell.execute_reply.started":"2024-05-25T20:02:11.454967Z","shell.execute_reply":"2024-05-25T20:02:11.458343Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"#### Train function","metadata":{}},{"cell_type":"code","source":"# Train\ndef train(model, dataloader, optimizer, criterion):\n    model.train()\n    running_loss = 0\n    total_steps = 0\n    for i, batch in enumerate(dataloader):\n        ft = batch['ft'].to(device).float()\n        gt = batch['gt'].to(device).float()\n\n        optimizer.zero_grad()\n        output = model(ft).squeeze()\n\n        loss = criterion(output, gt)\n        \n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        total_steps += 1\n    return running_loss/total_steps","metadata":{"execution":{"iopub.status.busy":"2024-05-25T19:44:47.045439Z","iopub.execute_input":"2024-05-25T19:44:47.045813Z","iopub.status.idle":"2024-05-25T19:44:47.053105Z","shell.execute_reply.started":"2024-05-25T19:44:47.045782Z","shell.execute_reply":"2024-05-25T19:44:47.051950Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"#### Eval function","metadata":{}},{"cell_type":"code","source":"def eval(model, dataloader):\n    model.eval()\n    acc = []\n    iou = []\n    f1 = []\n    total_steps = 0\n    with torch.no_grad():\n        for i, batch in enumerate(dataloader):\n            ft = batch['ft'].to(device)\n            gt = torch.flatten(batch['gt'])\n\n            output = torch.flatten(model(ft)).squeeze().cpu()\n            output = (output > 0.5)\n\n            acc.append(accuracy_score(gt, output))\n            iou.append(jaccard_score(gt, output))\n            f1.append(f1_score(gt, output))\n            total_steps += 1\n    return sum(acc)/total_steps, sum(iou)/total_steps, sum(f1)/total_steps","metadata":{"execution":{"iopub.status.busy":"2024-05-25T19:44:47.913318Z","iopub.execute_input":"2024-05-25T19:44:47.913983Z","iopub.status.idle":"2024-05-25T19:44:47.921263Z","shell.execute_reply.started":"2024-05-25T19:44:47.913948Z","shell.execute_reply":"2024-05-25T19:44:47.920214Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"#### Inference function\n\nSaves the inference results to a submission file!","metadata":{}},{"cell_type":"code","source":"def inference(model, dataloader):\n    model.eval()\n    with torch.no_grad():\n        cfire = torch.zeros(target_shape)\n        for i, day in enumerate(dataloader):\n            ft = day['ft'].to(device)\n\n            # Create the submission file after 10 days\n            if i > 9:\n                cfire = torch.logical_or(output, cfire) # define the cumulative fire\n                ft[0][1] = cfire # set the cumulative fire for the next input\n                ft[0][2] = output # set the next step fire for the next input\n            else:\n                cfire = ft[0][1]\n\n            output = model(ft)\n            output = (output > 0.5)\n    \n    # Save the cumulative fire\n    pred = cfire.cpu().squeeze().numpy()\n    save_df = pd.DataFrame(pred)  # convert img data to df\n    save_df.to_csv(\"submission.csv\", index_label='row')\n    return pred","metadata":{"execution":{"iopub.status.busy":"2024-05-25T19:44:48.876644Z","iopub.execute_input":"2024-05-25T19:44:48.877697Z","iopub.status.idle":"2024-05-25T19:44:48.884836Z","shell.execute_reply.started":"2024-05-25T19:44:48.877659Z","shell.execute_reply":"2024-05-25T19:44:48.883778Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"model = CNN1(num_features=8)\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = IoULoss()\nepochs = 100\nbest_miou = 0\nfor e in range(epochs):\n    loss = train(model, trainloader, optimizer, criterion)\n    aa, miou, mf1 = eval(model,valloader)\n\n    if miou > best_miou:\n        best_miou = miou\n        cfire = inference(model, testloader)\n        e = str(e)+\"*\"\n    print(e, \" avg iou loss:{:.3f} avg acc: {:.3f} avg f1: {:.3f} avg iou: {:.3f}\".format(loss, aa, mf1, miou))\n\n\n#### The training/eval/inference loop\n\n<ins>**Define new optimizers here**<ins>\n\n<ins>**Utilize a scheduler here**<ins>\n\n<ins>**Change the learning rate here**<ins>\n\n<ins>**Implement a better early stopping strategy here**<ins>\n\n<ins>**Implement other tricks here (i.e. EMA)**<ins>\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass FuelEmbeddings(nn.Module):\n    def __init__(self, embedding_dim):\n        super(FuelEmbeddings, self).__init__()\n\n        unique_values = [0, 1, 2, 3, 4, 7, 13, 31, 101, 425, 635, 650, 665]\n        self.unique_values = torch.tensor(unique_values).to(device)  # Unique values in the categorical feature\n        self.embedding_dim = embedding_dim\n        self.embedding = nn.Embedding(num_embeddings=len(unique_values), embedding_dim=embedding_dim)\n\n    def forward(self, categorical_feature):\n        # (B,H,W) -> (B,H,W,U) wher U is unique values count\n        mask = categorical_feature.unsqueeze(-1) == self.unique_values\n        matching_indices = torch.argmax(mask.int(), dim=-1)\n\n        # Apply embedding and reshape\n        # (B,H,W,U) -> (B,H,W,6) -> (B,6,H,W) in default setting\n        embedded_fuel = self.embedding(matching_indices)\n        embedded_reshaped_fuel = embedded_fuel.permute(0, 3, 1, 2)\n\n        return embedded_reshaped_fuel\n\nclass CNN1(nn.Module):\n    def __init__(self, embedding_dim=6, num_features=8):\n        super(CNN1, self).__init__()\n\n        self.fuelembedding = FuelEmbeddings(embedding_dim)\n\n        # (266, 433)\n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(in_channels=(embedding_dim+num_features-1), out_channels=8, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=8),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=16),\n            nn.ReLU(inplace=True)\n        )\n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(num_features=8),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=8, out_channels=1, kernel_size=3, stride=1, padding=1)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        categorical_feature = x[:, 0, :, :]  # Extract the categorical feature\n        embedded_fuel = self.fuelembedding(categorical_feature)  # Transform the categorical feature\n\n        # Replace the original categorical feature with the embedded feature\n        x = torch.cat((embedded_fuel, x[:, 1:, :, :]), dim=1)\n\n        x = self.conv_block1(x)\n        x = self.conv_block2(x)\n        out = self.sigmoid(x)\n\n        return out\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:07:37.964423Z","iopub.execute_input":"2024-05-25T20:07:37.965112Z","iopub.status.idle":"2024-05-25T20:07:37.980610Z","shell.execute_reply.started":"2024-05-25T20:07:37.965078Z","shell.execute_reply":"2024-05-25T20:07:37.979598Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model = CNN1(num_features=11)\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.002)\ncriterion = IoULoss()\nepochs = 50\nbest_miou = 0\n\n\nfor e in range(epochs):\n    loss = train(model, trainloader, optimizer, criterion)\n    aa, miou, mf1 = eval(model,valloader)\n\n    if miou > best_miou:\n        best_miou = miou\n        cfire = inference(model, testloader)\n        e = str(e)+\"*\"\n    print(e, \" avg iou loss:{:.3f} avg acc: {:.3f} avg f1: {:.3f} avg iou: {:.3f}\".format(loss, aa, mf1, miou))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:34:05.400170Z","iopub.execute_input":"2024-05-25T20:34:05.400535Z","iopub.status.idle":"2024-05-25T20:45:39.369274Z","shell.execute_reply.started":"2024-05-25T20:34:05.400505Z","shell.execute_reply":"2024-05-25T20:45:39.367669Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"0*  avg iou loss:0.993 avg acc: 0.792 avg f1: 0.029 avg iou: 0.015\n1*  avg iou loss:0.987 avg acc: 0.984 avg f1: 0.135 avg iou: 0.074\n2*  avg iou loss:0.915 avg acc: 0.992 avg f1: 0.317 avg iou: 0.190\n3*  avg iou loss:0.834 avg acc: 0.992 avg f1: 0.325 avg iou: 0.197\n4  avg iou loss:0.817 avg acc: 0.992 avg f1: 0.322 avg iou: 0.195\n5*  avg iou loss:0.818 avg acc: 0.991 avg f1: 0.333 avg iou: 0.201\n6*  avg iou loss:0.816 avg acc: 0.991 avg f1: 0.343 avg iou: 0.208\n7  avg iou loss:0.813 avg acc: 0.992 avg f1: 0.326 avg iou: 0.196\n8  avg iou loss:0.813 avg acc: 0.992 avg f1: 0.324 avg iou: 0.195\n9*  avg iou loss:0.815 avg acc: 0.992 avg f1: 0.352 avg iou: 0.214\n10  avg iou loss:0.806 avg acc: 0.992 avg f1: 0.348 avg iou: 0.212\n11  avg iou loss:0.800 avg acc: 0.994 avg f1: 0.295 avg iou: 0.175\n12  avg iou loss:0.808 avg acc: 0.992 avg f1: 0.336 avg iou: 0.203\n13  avg iou loss:0.808 avg acc: 0.992 avg f1: 0.349 avg iou: 0.212\n14  avg iou loss:0.799 avg acc: 0.992 avg f1: 0.350 avg iou: 0.212\n15*  avg iou loss:0.802 avg acc: 0.992 avg f1: 0.362 avg iou: 0.222\n16  avg iou loss:0.795 avg acc: 0.992 avg f1: 0.346 avg iou: 0.210\n17  avg iou loss:0.800 avg acc: 0.992 avg f1: 0.349 avg iou: 0.212\n18  avg iou loss:0.789 avg acc: 0.993 avg f1: 0.340 avg iou: 0.207\n19  avg iou loss:0.787 avg acc: 0.992 avg f1: 0.357 avg iou: 0.217\n20  avg iou loss:0.794 avg acc: 0.993 avg f1: 0.325 avg iou: 0.201\n21  avg iou loss:0.786 avg acc: 0.993 avg f1: 0.356 avg iou: 0.221\n22  avg iou loss:0.797 avg acc: 0.992 avg f1: 0.339 avg iou: 0.206\n23  avg iou loss:0.795 avg acc: 0.992 avg f1: 0.344 avg iou: 0.209\n24*  avg iou loss:0.786 avg acc: 0.993 avg f1: 0.376 avg iou: 0.233\n25  avg iou loss:0.789 avg acc: 0.993 avg f1: 0.365 avg iou: 0.224\n26  avg iou loss:0.798 avg acc: 0.990 avg f1: 0.311 avg iou: 0.186\n27  avg iou loss:0.798 avg acc: 0.993 avg f1: 0.328 avg iou: 0.201\n28  avg iou loss:0.793 avg acc: 0.992 avg f1: 0.332 avg iou: 0.203\n29  avg iou loss:0.791 avg acc: 0.992 avg f1: 0.365 avg iou: 0.225\n30  avg iou loss:0.791 avg acc: 0.992 avg f1: 0.351 avg iou: 0.214\n31  avg iou loss:0.799 avg acc: 0.993 avg f1: 0.364 avg iou: 0.224\n32  avg iou loss:0.789 avg acc: 0.992 avg f1: 0.348 avg iou: 0.215\n33  avg iou loss:0.791 avg acc: 0.993 avg f1: 0.374 avg iou: 0.231\n34  avg iou loss:0.790 avg acc: 0.992 avg f1: 0.367 avg iou: 0.226\n35  avg iou loss:0.792 avg acc: 0.993 avg f1: 0.365 avg iou: 0.223\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m best_miou \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     aa, miou, mf1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(model,valloader)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m miou \u001b[38;5;241m>\u001b[39m best_miou:\n","Cell \u001b[0;32mIn[8], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion)\u001b[0m\n\u001b[1;32m      4\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m total_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      7\u001b[0m     ft \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mft\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      8\u001b[0m     gt \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:171\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"model = CNN1(num_features=14)\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = IoULoss()\nepochs = 30\nbest_miou = 0\nfor e in range(epochs):\n    loss = train(model, trainloader, optimizer, criterion)\n    aa, miou, mf1 = eval(model,valloader)\n\n    if miou > best_miou:\n        best_miou = miou\n        cfire = inference(model, testloader)\n        e = str(e)+\"*\"\n    print(e, \" avg iou loss:{:.3f} avg acc: {:.3f} avg f1: {:.3f} avg iou: {:.3f}\".format(loss, aa, mf1, miou))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CNN1(num_features=12)\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = IoULoss()\nepochs = 15\nbest_miou = 0\nfor e in range(epochs):\n    loss = train(model, trainloader, optimizer, criterion)\n    aa, miou, mf1 = eval(model,valloader)\n\n    if miou > best_miou:\n        best_miou = miou\n        cfire = inference(model, testloader)\n        e = str(e)+\"*\"\n    print(e, \" avg iou loss:{:.3f} avg acc: {:.3f} avg f1: {:.3f} avg iou: {:.3f}\".format(loss, aa, mf1, miou))\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CNN1(num_features=8)\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = IoULoss()\nepochs = 15\nbest_miou = 0\nfor e in range(epochs):\n    loss = train(model, trainloader, optimizer, criterion)\n    aa, miou, mf1 = eval(model,valloader)\n\n    if miou > best_miou:\n        best_miou = miou\n        cfire = inference(model, testloader)\n        e = str(e)+\"*\"\n    print(e, \" avg iou loss:{:.3f} avg acc: {:.3f} avg f1: {:.3f} avg iou: {:.3f}\".format(loss, aa, mf1, miou))\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CNN1(num_features=8)\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = IoULoss()\nepochs = 100\nbest_miou = 0\nfor e in range(epochs):\n    loss = train(model, trainloader, optimizer, criterion)\n    aa, miou, mf1 = eval(model,valloader)\n\n    if miou > best_miou:\n        best_miou = miou\n        cfire = inference(model, testloader)\n        e = str(e)+\"*\"\n    print(e, \" avg iou loss:{:.3f} avg acc: {:.3f} avg f1: {:.3f} avg iou: {:.3f}\".format(loss, aa, mf1, miou))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Other Ideas to implement!\n\n<ins>**Ensemble learning - voting**<ins>\n\n<ins>**Implement hot spot data pipeline**<ins>\n\n<ins>**Make better use of temporal data**<ins>\n\n<ins>**Get creative!**<ins>","metadata":{}}]}